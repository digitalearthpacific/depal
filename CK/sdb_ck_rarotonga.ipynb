{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Near Shore Satellite Derived Bathymetry Using AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from odc.stac import load\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from odc.algo import mask_cleanup\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"ck_rarotonga_depth_points.gpkg\")\n",
    "gdf.depth.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reduced = gdf[gdf[\"depth\"] < 50]\n",
    "sample1 = reduced.sample(3500)\n",
    "#sample2 = reduced.sample(2500)\n",
    "reduced.explore(column=\"depth\", cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "catalog = \"https://earth-search.aws.element84.com/v1\"\n",
    "client = Client.open(catalog)\n",
    "\n",
    "# Get extents of gdf\n",
    "bbox = list(gdf.to_crs(\"epsg:4326\").total_bounds)\n",
    "\n",
    "# Expand the bbox slightly\n",
    "buffer = 0.01\n",
    "bbox[0] = bbox[0] - buffer\n",
    "bbox[1] = bbox[1] - buffer\n",
    "bbox[2] = bbox[2] + buffer\n",
    "bbox[3] = bbox[3] + buffer\n",
    "\n",
    "items = client.search(\n",
    "    collections=[\"sentinel-2-c1-l2a\"],\n",
    "    bbox=bbox,\n",
    "    datetime=\"2024-01/2024-09\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 30}},\n",
    ").item_collection()\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\n",
    "    items,\n",
    "    chunks={},\n",
    "    bbox=bbox,\n",
    "    groupby=\"solar_day\",\n",
    "    measurements=[\n",
    "        \"red\",\n",
    "        \"green\",\n",
    "        \"blue\",\n",
    "        \"nir\",\n",
    "        \"nir09\",\n",
    "        \"swir16\",\n",
    "        \"swir22\",\n",
    "        \"coastal\",\n",
    "        \"rededge1\",\n",
    "        \"rededge2\",\n",
    "        \"rededge3\",\n",
    "        \"scl\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# nodata, cloud shadow, medium cloud, high cloud\n",
    "mask_flags = [1, 3, 8, 9]\n",
    "cloud_mask = ~data.scl.isin(mask_flags)\n",
    "masked = data.where(cloud_mask).drop_vars(\"scl\")\n",
    "\n",
    "scaled = (masked.where(masked != 0) * 0.0001).clip(0, 1)\n",
    "\n",
    "scaled = scaled.compute()\n",
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some indices including NDVI, MNDWI, NDWI\n",
    "scaled[\"ndvi\"] = (scaled.nir - scaled.red) / (scaled.nir + scaled.red)\n",
    "scaled[\"ndwi\"] = (scaled.green - scaled.nir) / (scaled.green + scaled.nir)\n",
    "scaled[\"mndwi\"] = (scaled.green - scaled.swir16) / (scaled.green + scaled.swir16)\n",
    "\n",
    "# Create a single median\n",
    "median = scaled.median(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(col=\"time\", col_wrap=2, vmin=0, vmax=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(size=6, vmin=0, vmax=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprojected = sample1.to_crs(median.odc.crs)\n",
    "\n",
    "# Convert the geodataframe to an xarray\n",
    "pts_da = sample1.assign(x=reprojected.geometry.x, y=reprojected.geometry.y).to_xarray()\n",
    "\n",
    "# Extract values from the EO data onto the points xarray, and convert back to pandas\n",
    "pt_values_i = (\n",
    "    median.sel(pts_da[[\"x\", \"y\"]], method=\"nearest\").squeeze().compute().to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_array = pd.concat([sample1, pt_values_i], axis=1)\n",
    "training_array = training_array.drop(\n",
    "    columns=[\n",
    "        \"y\",\n",
    "        \"x\",\n",
    "        \"spatial_ref\",\n",
    "        \"geometry\",\n",
    "        #\"index_left\"\n",
    "    ]\n",
    ")\n",
    "# Drop rows where there are any NaNs\n",
    "training_array = training_array.dropna()\n",
    "\n",
    "training_array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(training_array)[:, 1:]\n",
    "values = np.array(training_array)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*AdaBoost* regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = AdaBoostRegressor(\n",
    "    #n_estimators=500,\n",
    "    #random_state=10\n",
    ")\n",
    "\n",
    "model = regr.fit(training_data, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in range(len(scaled.time)):\n",
    "    one_time = scaled.isel(time=i)\n",
    "\n",
    "    # Replace nans with -9999\n",
    "    one_time = one_time.fillna(-9999)\n",
    "\n",
    "    stacked_arrays = one_time.to_array().stack(dims=[\"y\", \"x\"]).transpose()\n",
    "\n",
    "    p = model.predict(stacked_arrays)\n",
    "    array = p.reshape(len(masked.y), len(masked.x))\n",
    "    predictions.append(xr.DataArray(\n",
    "        array, coords={\"x\": masked.x, \"y\": masked.y}, dims=[\"y\", \"x\"]\n",
    "    ))\n",
    "\n",
    "print(f\"Completed predicting {len(scaled.time)} time slices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions into an xarray\n",
    "predicted = xr.concat(predictions, dim=scaled.time).to_dataset(name=\"depth\")\n",
    "predicted = predicted.where(cloud_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted.depth.plot.imshow(col=\"time\", col_wrap=2, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = predicted.depth.median(\"time\")  # Use mean or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Assessment\n",
    "# Closer to 1 is better\n",
    "model.score(training_data, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Water/Land\n",
    "water = ((median.mndwi + median.ndwi) > 0)\n",
    "water_filtered = mask_cleanup(water, [(\"opening\", 5)])\n",
    "final = average.where(water_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = (bbox[1] + bbox[3])/2, (bbox[0] + bbox[2])/2\n",
    "m = folium.Map(location=coords, zoom_start=12, layer_control=True)\n",
    "\n",
    "tile = folium.TileLayer(\n",
    "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "    attr=\"World Imagery\",\n",
    "    overlay=False,\n",
    "    control=True\n",
    ").add_to(m)\n",
    "\n",
    "visual = median.odc.to_rgba([\"red\", \"green\", \"blue\"], vmin=0, vmax=0.3)\n",
    "visual.odc.add_to(m, name=\"RGB\")\n",
    "\n",
    "predicted.isel(time=0).depth.odc.add_to(m, name=\"Depth\", cmap=\"Blues\")\n",
    "average.odc.add_to(m, name=\"Average Depth\", cmap=\"Blues\")\n",
    "final.odc.add_to(m, name=\"Final Depth\", cmap=\"Blues\")\n",
    "\n",
    "# Layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.odc.write_cog(\"ck_rarotonga_depth.tif\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
